{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shapely'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-abf9b14c8572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shapely'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "from shapely.geometry import Point, Polygon\n",
    "from collections import Counter\n",
    "import geopandas\n",
    "from geopy.geocoders import Nominatim\n",
    "import warnings\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/complete.csv')\n",
    "# Controllo come vengono indicizzate le variabili\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi argomentativa\n",
    "Quali sono le keywords piú frequenti?\n",
    "1) Keywords totali piú frequenti\n",
    "\n",
    "2) Frequenza annuale di quelle frequenti\n",
    "\n",
    "3) Prendere in esempio le keywords di riferimento sulla mappa dei fatti di trento, guardare se hanno pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={\n",
    "    \"Argomenti:\" : \"\",\n",
    "    \"furto\" : \"furti\",\n",
    "    \"orso\" : \"orsi\",\n",
    "    \"trasporto\" : \"trasporti\",\n",
    "}\n",
    "\n",
    "for key in dictionary.keys():\n",
    "    df[\"keywords\"] = df[\"keywords\"].str.replace(key, dictionary[key])\n",
    "df[\"keywords\"] = df[\"keywords\"].apply(lambda x: re.findall('\\'([^\\']*)\\'', str(x))) # Transform string into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueKeyword(listaInDataframe):\n",
    "    #df_temp = df[df['year']=='2019']\n",
    "    temp_l = list(listaInDataframe)\n",
    "    temp_l = [j for i in temp_l for j in i]\n",
    "    cnt = Counter(temp_l)\n",
    "\n",
    "    key_value_count = cnt.most_common()\n",
    "    key_value_count.sort(key= lambda x: x[1], reverse=True)\n",
    "    total_keywords = [[x,y] for x,y in key_value_count]\n",
    "    #print(len(total_keywords))\n",
    "    return total_keywords\n",
    "\n",
    "totalKey = uniqueKeyword(df[\"keywords\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(totalKey[1:20], columns=['key', 'count']).to_csv(\"../newSite/src/best50key.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somma totale di tutte le keyword uniche \n",
    "len(totalKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studio la variazione delle keywords per ogni anno. Quali sono i trend topic annuali?\n",
    "years = df.year.unique()\n",
    "\n",
    "for year in years:\n",
    "    df_year = df[df['year']==year]\n",
    "    keywords = list(uniqueKeyword(df_year['keywords']))[:21]\n",
    "    keywds = []\n",
    "    for key in keywords:\n",
    "        if(key[0] != ''):\n",
    "            keywds.append(key)\n",
    "    print(year)\n",
    "    print(keywds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi Temporale\n",
    "Frequenza degli articoli annuali, quanti articoli escono all'anno? qual è la crescita? \n",
    "\n",
    "* Quali sono i mesi piú caldi dal punto di vista dell'informazione? Anni?\n",
    "\n",
    "Lo studio ha dimostrato che per quanto riguarda gli anni non c'è una sostanziale crescita o decrescita dal punto di vista della pubblicazione degli articoli. In genere parliamo di una media di 3000 articoli l'anno che possono variare nell'ordine delle centinaia. I dati del 2020 non sono completi poiché si fermano ad inizio Novembre ma vedendo l'andamento degli anni precedenti si puó stimare una pubblicazione di altri ______ articoli.\n",
    "L'analisi che segue mostra l'andamento delle pubblicazioni in ordine temporale. La prima immagine descrive l'analisi annuale e la seconda l'andamento mensile nel corso di 8 anni di pubblicazioni.\n",
    "A spiccare sono proprio alcuni mesi che vedono un picco di crescita nell'ordine delle centinaia di articoli. I mesi in questione sono spesso quelli di ritorno dalle vacanze estive come Settembre ed Ottobre. \n",
    "Il 2020 é un anno particolare da questo punto di vista, complice la pandemia. Infatti vediamo come nel periodo di Marzo, Aprile le pubblicazioni siano state piú alte della norma, per non parlare di una fortissima diminuzione ad Agosto, riscontrata ogni anno ma accentuata in questo specifico periodo, ed una ripresa impressionante al ritorno delle vacanze che ha portato ad un divario tra agosto e ottobre di circa 150 articoli in piú.\n",
    "\n",
    "Analizzando quelli che sono gli argomenti principali dei vari mesi ovviamente il coronavirus é il trend topic di questo 2020. \n",
    "Ricordarsi che il grafico deve avere per ogni punto anche il topic principale del mese.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentazione groupby per le frequenze delle date\n",
    "year_frequency = df.groupby(pd.Grouper(key='timestamp', freq='1Y')).size().reset_index(name='counts')\n",
    "month_frequency = df.groupby(pd.Grouper(key='timestamp', freq='1M')).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_frequency['timestamp'] = year_frequency['timestamp'].apply(lambda x: x.strftime(\"%Y\"))\n",
    "year_frequency.to_csv(\"../newSite/src/countPerYear.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_frequency['timestamp'] = month_frequency['timestamp'].apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "\n",
    "month_frequency.to_csv(\"../newSite/src/countPerMonth.csv\", index=False)\n",
    "month_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(30,10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "y = year_frequency['timestamp'].to_list()\n",
    "c = year_frequency['counts'].to_list()\n",
    "plt.plot(y,c)\n",
    "plt.xticks(y)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(50,10), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "y = month_frequency['timestamp'].to_list()\n",
    "c = month_frequency['counts'].to_list()\n",
    "ax = plt.plot(y,c)\n",
    "plt.xticks(y)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo studio porta a pensare che ci sono mesi che hanno dei picchi particolari, come Settembre ed ottobre. Controllo i top 15 mesi per frequenza e trovo 8 su 15 sono settembre ed ottobre rispetto agli altri mesi. Ma cosa pubblicano?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(month_frequency.sort_values('counts', ascending=True).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Come ha cambiato gli argomenti il coronavirus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duemila19 = df.loc[(df['timestamp'].dt.year == 2019)]\n",
    "listaKey2019 = uniqueKeyword(duemila19[\"keywords\"])\n",
    "duemila20 = df.loc[(df['timestamp'].dt.year == 2020)]\n",
    "listaKey2020 = uniqueKeyword(duemila20[\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argomenti2anni = pd.DataFrame(zip(listaKey2019,listaKey2020), columns=[2019,2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(argomenti2anni.head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondo approccio\n",
    "Comparo i best key del 2019 e vedo che cambiamento in fatto di numeri hanno avuto nel 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019, 2020]\n",
    "\n",
    "df_year = df[df['year']==2019]\n",
    "keywords2019 = list(uniqueKeyword(df_year['keywords']))[:21]\n",
    "keys = []\n",
    "key2019 = []\n",
    "for key in keywords2019:\n",
    "    if(key[0] != ''):\n",
    "        keys.append(key[0])\n",
    "        key2019.append(key)\n",
    "key2019 = dict(key2019)\n",
    "key2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = df[df['year']==2020]\n",
    "keywords2020 = list(uniqueKeyword(df_year['keywords']))\n",
    "key2020 =[]\n",
    "for key in keywords2020:\n",
    "    if((key[0] != '') and (key[0] in keys) ):\n",
    "        key2020.append(key)\n",
    "key2020 = dict(key2020)\n",
    "key2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['keys', 'diciannove', 'venti']\n",
    "ordered2020 = []\n",
    "for key in keys:\n",
    "    ordered2020.append(key2020.get(key))\n",
    "pd.DataFrame(list(zip(keys,key2019.values() ,ordered2020 )), columns=cols).to_csv(\"../newSite/src/compared20192020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi mensile top Keyword\n",
    "Abbiamo visto negli ultimi anni Ottobre e le sue argomentazioni, ma quali sono le keywords che hanno caratterizzato ogni mese nel corso degli anni?\n",
    "\n",
    "Per poterlo realizzare posso utilizzare le funzioni che ho giá creato e ciclarle per creare quello che mi serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for year in range(2012,2021):\n",
    "    \n",
    "    # ciclo sui mesi\n",
    "    for month in range(1,13):\n",
    "        data = df.loc[(df['timestamp'].dt.month == month)&(df['timestamp'].dt.year == year)]\n",
    "        lista = uniqueKeyword(data[\"keywords\"])\n",
    "        #print(year, month, lista[:3])\n",
    "        rows.append(lista[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.array([2012]*12 +[2013]*12 +[2014]*12 +[2015]*12 +[2016]*12 +[2017]*12 +[2018]*12 +[2019]*12 +[2020]*12), \n",
    "          np.array([1,2,3,4,5,6,7,8,9,10,11,12]*9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dato = pd.DataFrame(rows, index=arrays, columns=range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(dato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi Geografica\n",
    "L'analisi geografica qui rappresentata prende come riferimento il dataset geolocalizzato e lo studia per quelle che possno essere le componenti geografiche e le componenti argomentative.\n",
    "\n",
    "Qui rispondiamo a domande come:\n",
    "* Quali sono i topic piú trattati per le notizie geolocalizzate? In questo modo possiamo vedere che tipo di notizie andiamo a trattare. Mi aspetto che siano notizie prevalentemente di incidenti, strade, notizie di quartiere.\n",
    "* Tra queste notizie quali sono le piú comuni su trento?\n",
    "* Quali sono i quartieri di trento con piú notizie?\n",
    "* C'è una sostanziale differenza tra il centro e la periferia?\n",
    "* Trento VS Comuni. Quali sono le notizie e che tipo di notizie sono quelle nei comuni?\n",
    "* Occhio mirato sulla criminalità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "from shapely.geometry import Point, Polygon\n",
    "from collections import Counter\n",
    "import geopandas\n",
    "from geopy.geocoders import Nominatim\n",
    "import warnings\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/complete.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df['comune'].notnull())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I punti trovati in trentino sono 19.216.\n",
    "\n",
    "Quali sono i topic piú trattati per le notizie geolocalizzate? In questo modo possiamo vedere che tipo di notizie andiamo a trattare. Mi aspetto che siano notizie prevalentemente di incidenti, strade, notizie di quartiere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={\n",
    "    \"Argomenti:\" : \"\",\n",
    "    \"furto\" : \"furti\",\n",
    "    \"orso\" : \"orsi\",\n",
    "}\n",
    "\n",
    "for key in dictionary.keys():\n",
    "    df[\"keywords\"] = df[\"keywords\"].str.replace(key, dictionary[key])\n",
    "df[\"keywords\"] = df[\"keywords\"].apply(lambda x: re.findall('\\'([^\\']*)\\'', str(x))) # Transform string into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueKeyword(listaInDataframe):\n",
    "    #df_temp = df[df['year']=='2019']\n",
    "    temp_l = list(listaInDataframe)\n",
    "    temp_l = [j for i in temp_l for j in i]\n",
    "    cnt = Counter(temp_l)\n",
    "\n",
    "    key_value_count = cnt.most_common()\n",
    "    key_value_count.sort(key= lambda x: x[1], reverse=True)\n",
    "    total_keywords = [[x,y] for x,y in key_value_count]\n",
    "    #print(len(total_keywords))\n",
    "    return total_keywords\n",
    "\n",
    "trento = df[df['comune'] == 'Trento' ]\n",
    "trentino = df[(df['comune'].notnull())]\n",
    "nonTrento = df[(df['comune'].notnull())&(df['comune']!=\"Trento\")]\n",
    "totalKey = uniqueKeyword(df[\"keywords\"])\n",
    "nonTrentoKey = uniqueKeyword(nonTrento[\"keywords\"])\n",
    "trentoKey = uniqueKeyword(trento[\"keywords\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numero di punti in trentino: \",len(trentino))\n",
    "print(\"Numero di punti nei comuni: \",len(nonTrento))\n",
    "print(\"Keywors più utilizzate nei comuni: \\n\", nonTrentoKey[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonTrentoKey\n",
    "keywds = []\n",
    "for key in nonTrentoKey:\n",
    "    if(key[0] != ''):\n",
    "        keywds.append(key)\n",
    "pd.DataFrame(keywds[:20], columns=['key', 'count']).to_csv(\"/home/frabatx/Documents/University/Data_journalism/Project_Article/today_parser/newSite/src/comuni20key.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numero di punti a Trento: \",len(trento))\n",
    "print(\"Keywors più utilizzate a Trento: \\n\",trentoKey[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentuale di notizie su trento\")\n",
    "print((11343/19216)*100), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo ci fa capire che le notizie sul coronavirus sono date prevalentemente su Trento, considerando che piú della metá sono geolocalizzate in cittá e solo 69 sono rivolte ai comuni.\n",
    "\n",
    "Come era prevedibile le notizie principali per i comuni sono gli incidenti, quello che stupisce é che le notizie sui furti siano maggiori nei comuni che in cittá. In realtá non so bene come descrivere quello che ho trovato in questo contesto. Magari é utile contestualizzare il tutto con una mappa che definisce i comuni piú pericolosi magari. Faccio il dataset e vedo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countArticleComune = nonTrento.groupby(['comune']).size().reset_index(name='counts').sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controllo se i comuni che hanno piú articoli sono i piú grandi del Trentino. La risposta é no. Le cittá con piú articoli sono quelle con popolazione maggiore in ordine di densitá di popolazione!!\n",
    "https://www.tuttitalia.it/trentino-alto-adige/provincia-autonoma-di-trento/88-comuni/popolazione/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import geopandas as gpd\n",
    "fiona.listlayers('data/istat_administrative_units_2020.gpkg')\n",
    "municipalities = gpd.read_file(\"data/istat_administrative_units_2020.gpkg\",\n",
    "                               layer=\"municipalities\", \n",
    "                               GEOM_POSSIBLE_NAMES=\"geometry\",\n",
    "                               KEEP_GEOM_COLUMNS=\"NO\")\n",
    "# filter the province\n",
    "municipalities_province_trento = municipalities[municipalities.COD_PROV==22]\n",
    "municipalities_province_trento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities_province_trento.to_crs(\"EPSG:4326\", inplace=True)\n",
    "municipalities_province_trento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities_province_trento['areas'] = municipalities_province_trento['geometry'].area/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities_province_trento = municipalities_province_trento[['COMUNE', 'areas']].sort_values('areas', ascending=False)\n",
    "municipalities_province_trento = municipalities_province_trento.rename(columns={'COMUNE': 'comune'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.merge(countArticleComune, municipalities_province_trento, how='outer', on=['comune']).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controllo quali sono i comuni che hanno piú criminalitá in base alle key che ho trovato:\n",
    "* Furti\n",
    "* Incidenti"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parolaChiave = nonTrento[nonTrento['keywords'].apply(lambda x: 'incidenti' in x)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "print(parolaChiave.groupby(['year', 'comune']).size().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analisi dei furti nei comuni,divisi per anni fanno capire che sono notizie sparse, non di particolare rilevanza, certo il numero dei comuni li fa spiccare rispetto a Trento, in realtá dipende dal numero.\n",
    "Rovereto é quella che tra tutti è la piú rilevante, nulla di particolarmente rilevante rispetto a trento, un massimo di 10 notizie annuali.\n",
    "Queste analisi stanno portando alla conclusione che la principale fonte di notizie sia Trento e non il Trentino."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "#df_quartieri = pd.read_csv('data/poli_sociali.csv', delimiter=';')\n",
    "#df_quartieri = geopandas.read_file('data/poli_sociali.csv')\n",
    "# loading polygons geodataframe\n",
    "gdf_polygons = gpd.read_file('data/poli_sociali/poli_sociali.shp')\n",
    "gdf_polygons.to_crs(\"EPSG:4326\", inplace=True)\n",
    "#gdf_polygons"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counts_df = gdf_polygons.merge(conteggioQuartieriDf, how='inner',left_on=['cod_quart', 'nome_quart'],right_on=['cod_quart', 'nome_quart'])\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counts_df = counts_df[['counts', 'cod_quart','nome_quart', 'geometry']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counts_df['geometry'] = counts_df['geometry'].apply(lambda x : shapely.geometry.Polygon(x)) \n",
    "type(counts_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counts_df.to_file(\"/home/frabatx/Documents/University/Data_journalism/Project_Article/today_parser/newSite/src/countQuartieri.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conto gli articoli nei comuni e li trasformo in geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countArticleTrentino = trentino.groupby(['comune']).size().reset_index(name='counts').sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities_province_trento['geometry'] = municipalities_province_trento['geometry'].apply(lambda x : shapely.geometry.MultiPolygon(x)) \n",
    "municipalities_province_trento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_comuni = municipalities_province_trento.merge(countArticleTrentino, how='left',left_on=['COMUNE'],right_on=['comune'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_comuni = df_counts_comuni[['comune', 'counts', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "df_counts_comuni['geometry'] = df_counts_comuni['geometry'].apply(lambda x : shapely.geometry.MultiPolygon(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_comuni.to_file(\"/home/frabatx/Documents/University/Data_journalism/Project_Article/today_parser/newSite/src/countComuni.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_comuni.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi Trento\n",
    "\n",
    "* Qual è il quartiere con piú notizie? Che tipo di notizie ci sono?\n",
    "\n",
    "Un problema che ho notato é che il dataset Trento pinga le notizie in centro storico anche quando é solo \"Trento\" come geolocalizzazione. \n",
    "Vedo di togliere quelle che hanno address solo Trento. Facendolo perdo 1000 punti ma quello che ne ricavo é la geolocalizzazione di solo punti che hanno address centro storico.\n",
    "Ora posso fare l'analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolgo gli address che contengono solo Trento perché vengono pingati in =centro storico\n",
    "trento = trento[trento['address']!=\"Trento\"]\n",
    "trentoKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteggioQuartieriDf = trento.groupby(['nome_quart', 'cod_quart']).size().reset_index(name='counts').sort_values('counts', ascending=False)\n",
    "conteggioQuartieriDf['cod_quart'] = conteggioQuartieriDf['cod_quart'].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteggioQuartieriDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "#df_quartieri = pd.read_csv('data/poli_sociali.csv', delimiter=';')\n",
    "#df_quartieri = geopandas.read_file('data/poli_sociali.csv')\n",
    "# loading polygons geodataframe\n",
    "gdf_polygons = gpd.read_file('data/poli_sociali/poli_sociali.shp')\n",
    "gdf_polygons.to_crs(\"EPSG:4326\", inplace=True)\n",
    "#gdf_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = gdf_polygons.merge(conteggioQuartieriDf, how='inner',left_on=['cod_quart', 'nome_quart'],right_on=['cod_quart', 'nome_quart'])\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = counts_df[['counts', 'cod_quart','nome_quart', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df['geometry'] = counts_df['geometry'].apply(lambda x : shapely.geometry.Polygon(x)) \n",
    "type(counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformo i dati in json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#counts_df.to_csv('./data/countsComuni.csv', index=False)\n",
    "#geojson = counts_df.to_json()\n",
    "counts_df.to_file(\"/home/frabatx/Documents/University/Data_journalism/Project_Article/today_parser/newSite/src/countQuartieri.geojson\", driver='GeoJSON')\n",
    "#counts_df.to_geojson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('/home/frabatx/Documents/University/Data_journalism/Project_Article/today_parser/newSite/src/countQuartieri.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(geojson, f, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizzo quali sono le principali notizie per tipo di quartiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartieri = trento['nome_quart'].unique()\n",
    "quartieri = [i for i in quartieri]\n",
    "print(type(quartieri))\n",
    "print(len(np.array(quartieri*9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array([2012]*len(quartieri) +[2013]*len(quartieri) +[2014]*len(quartieri) +[2015]*len(quartieri) +[2016]*len(quartieri) +[2017]*len(quartieri) +[2018]*len(quartieri) +[2019]*len(quartieri) +[2020]*len(quartieri)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for quartiere in quartieri:\n",
    "    data = trento.loc[trento['nome_quart'] == str(quartiere)]\n",
    "    lista = uniqueKeyword(data[\"keywords\"])\n",
    "    #print(year, month, lista[:3])\n",
    "    rows.append(lista[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.array(quartieri)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dato = pd.DataFrame(rows, index=arrays, columns=range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(dato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dove sono collocate le notizie di furti e droga?\n",
    "trento[trento['keywords'].apply(lambda x: 'droga' in x)].groupby(['nome_quart']).size().reset_index(name='counts').sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il centro storico é quello piú rappresentativo della cittá \n",
    "centro = trento[trento['nome_quart']== \"Centro Storico\".upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centro[centro['keywords'].apply(lambda x: 'droga' in x)].groupby(pd.Grouper(key='timestamp', freq = '1Y')).size().reset_index(name='counts').to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centro[(centro['keywords'].apply(lambda x: 'droga' in x))&(centro['year'] == 2016)]['title'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trento[trento['keywords'].apply(lambda x: 'furti' in x)].groupby(['nome_quart']).size().reset_index(name='counts').sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trento[trento['keywords'].apply(lambda x: 'droga' in x)].groupby(['nome_quart']).size().to_string())#.sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centro[centro['keywords'].apply(lambda x: 'furti' in x)].groupby(pd.Grouper(key='timestamp', freq = '1Y')).size().reset_index(name='counts').to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trento[trento['keywords'].apply(lambda x: 'droga' in x)].groupby(pd.Grouper(key='timestamp', freq = '1Y')).size().reset_index(name='counts').to_csv(\"/home/frabatx/Documents/University/Data_journalism/Project_Article/today_parser/newSite/src/drogaTrento.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trento[trento['keywords'].apply(lambda x: 'furti' in x)].groupby(pd.Grouper(key='timestamp', freq = '1Y')).size().reset_index(name='counts').to_csv(\"/home/frabatx/Documents/University/Data_journalism/Project_Article/today_parser/newSite/src/furtiTrento.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centro[(centro['keywords'].apply(lambda x: 'furti' in x))&(centro['year'] == 2016)]['title'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi Argomentativa\n",
    "In questa analisi studio le co-occorrenze tra le keywords per capire se in qualche modo alcuni argomenti possano essere collegati e trovare qualche relazione in particolare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "from shapely.geometry import Point, Polygon\n",
    "from collections import Counter\n",
    "import geopandas\n",
    "from geopy.geocoders import Nominatim\n",
    "import warnings\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/complete.csv')\n",
    "# Controllo come vengono indicizzate le variabili\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={\n",
    "    \"Argomenti:\" : \"\",\n",
    "    \"furto\" : \"furti\",\n",
    "    \"orso\" : \"orsi\",\n",
    "}\n",
    "\n",
    "for key in dictionary.keys():\n",
    "    df[\"keywords\"] = df[\"keywords\"].str.replace(key, dictionary[key])\n",
    "df[\"keywords\"] = df[\"keywords\"].apply(lambda x: re.findall('\\'([^\\']*)\\'', str(x))) # Transform string into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique keywords\n",
    "def uniqueKeyword(listaInDataframe):\n",
    "    #df_temp = df[df['year']=='2019']\n",
    "    temp_l = list(listaInDataframe)\n",
    "    temp_l = [j for i in temp_l for j in i]\n",
    "    cnt = Counter(temp_l)\n",
    "\n",
    "    key_value_count = cnt.most_common()\n",
    "    key_value_count.sort(key= lambda x: x[1], reverse=True)\n",
    "    total_keywords = [[x,y] for x,y in key_value_count]\n",
    "    #print(len(total_keywords))\n",
    "    return total_keywords\n",
    "\n",
    "total_keywords = uniqueKeyword(df[\"keywords\"])\n",
    "list(total_keywords[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common200 = total_keywords[:20]\n",
    "mostCommonKey = [row[0] for row in common200[1:]] # seleziono le prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(50,30), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Creo una lista boleana \n",
    "def filter_df(initial_column, key):\n",
    "    return key in initial_column\n",
    "\n",
    "def correlationDataFrame(keywords, df, stringKeywordsColumnName):\n",
    "    matrix = []\n",
    "    for index, key in enumerate(keywords):\n",
    "        row = [0] * len(keywords)\n",
    "        boolean = df[stringKeywordsColumnName].apply(lambda x: filter_df(x, key))\n",
    "        filtered_df = df[boolean]\n",
    "        super_lista = []\n",
    "        for lista in filtered_df[stringKeywordsColumnName]:\n",
    "            super_lista.extend(lista)\n",
    "        for indice, chiave in enumerate(keywords):\n",
    "            #print('index = {}, conto = {}, chiave = {}'.format(indice, super_lista.count(chiave), chiave))\n",
    "            row[indice] = super_lista.count(chiave)\n",
    "        #normalizzo la righa, quindi il grafico non potrá essere letto per colonne\n",
    "        valoremassimo = max(row)\n",
    "        normalizzata = [x / valoremassimo for x in row]\n",
    "        matrix.append(normalizzata)\n",
    "        \n",
    "    corrdf = pd.DataFrame(np.triu(matrix), columns=keywords, index=keywords)\n",
    "    \n",
    "    return  corrdf\n",
    "\n",
    "corrdf = correlationDataFrame(mostCommonKey, df, 'keywords')\n",
    "corrdf.to_csv('correlation.csv')\n",
    "\n",
    "\n",
    "plt.pcolor(corrdf)\n",
    "plt.yticks(np.arange(0.5, len(corrdf.index), 1), corrdf.index)\n",
    "plt.xticks(np.arange(0.5, len(corrdf.columns), 1), corrdf.columns)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for index, row in corrdf.iterrows():\n",
    "    print(row.apply(lambda x: x if x>0.3 else None).to_string())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l'analisi argomentativa ha portato a capire che nessuna keyword é particolarmente corelata. Pensiamo che sulle prime 200 é stata trovata solo una correlazione che superasse lo 0.4, che comunque é una correlazione debole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
